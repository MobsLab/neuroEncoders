#!/usr/bin/env python
# neuroEncoder by the Memory, Oscillations and Brain States (MOBS) team
# 2017-2024
# by Thibault Balenbois, Pierre Orhan, Dmitri Bryzgalov and ThÃ©otime de Charrin
# t.balenbois@gmail.com; brygalovdm@gmail.com; theotime.decharrin@gmail.com

import os
import subprocess

# Load standard libs
import sys
from warnings import warn

from numpy import max as np_max
import numpy as np
import pandas as pd
import shutil


from neuroencoders.importData.epochs_management import inEpochsMask

# Load custom code
from neuroencoders.utils.global_classes import DataHelper as DataHelperClass
from neuroencoders.utils.global_classes import Params, Project, save_project_to_pickle

# Meta parameters
show_figures = False
debug = True
overWrite_speed_filter_and_linearization = False


def main(args):
    # WARNING: This is a very long function, consider splitting it?
    # NOTE: The "nnBehavior.mat" file is already created when executing main func see `getTsdFeature.sh`.
    # Manage inputs
    if not args.mode == "bayes":
        if args.gpu:
            from neuroencoders.utils import management

            deviceName = management.manage_devices("GPU", set_memory_growth=True)
        else:
            os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
            os.environ["CUDA_VISIBLE_DEVICES"] = ""
            from neuroencoders.utils import management

            deviceName = management.manage_devices("CPU")
    if args.mode == "decode":
        jsonPath = os.path.expanduser(args.jsonPath)
    else:
        jsonPath = None

    from neuroencoders.importData import rawdata_parser
    from neuroencoders.resultAnalysis import print_results
    from neuroencoders.transformData.linearizer import UMazeLinearizer

    # Output to shell
    print()
    if not args.mode == "bayes":
        print("NEUROENCODER: DEVICE", deviceName)
    xmlPath = args.path.strip("'")
    print("NEUROENCODER: PATH", xmlPath)
    # WARNING: windowSize is in s and gets converted to ms
    windowSizeMS = int(args.window * 1000)
    print(f"NEUROENCODER: WINDOW {windowSizeMS} ms")
    mode = args.mode
    print("NEUROENCODER: MODE", mode)
    if mode != "bayes":
        isPL = args.predicted_loss
        if isPL:
            print(
                "Two networks will be tested: one full on training set and "
                "one with predLoss only on a separate part of data"
            )
    else:
        isPL = False
    print()

    # Get behavior and tune parameters
    ProjectPath = Project(
        os.path.expanduser(xmlPath),
        jsonPath=jsonPath,
        nameExp=args.name,
        windowSize=args.window,
    )
    # Select the data for testing
    if mode != "decode":
        try:
            rawdata_parser.speed_filter(
                ProjectPath.folder,
                overWrite=args.redo and overWrite_speed_filter_and_linearization,
                phase=args.phase,
                window_range=2000,
                force=True
                if (args.phase is not None and not show_figures and not args.redo)
                else False,
            )
        except Exception as e:
            # If an IndexError occurs, it means that the speed filter failed
            print(f"Error during speed filter: {e}")
            args.phase = None
            rawdata_parser.speed_filter(
                ProjectPath.folder,
                overWrite=args.redo and overWrite_speed_filter_and_linearization,
                phase=args.phase,
                force=False,
            )
            warn(
                f'"IndexError" occurred for {ProjectPath.folder}, setting phase to None.'
            )
        rawdata_parser.select_epochs(
            ProjectPath.folder,
            overWrite=(True if (args.redo and args.phase is not None) else False),
            phase=args.phase,
            force=True if (args.phase is not None and not show_figures) else False,
            find_best_sets=True,
        )
    # Create parameters
    DataHelper = DataHelperClass(
        ProjectPath.xml,
        mode=mode,
        target=args.target,
        phase=args.phase,
        nameExp=args.name,
        windowSize=args.window,
        force_ref=False,
        isPredLoss=isPL,
    )
    helpers = [DataHelper]
    if args.phase != "cond":
        rawdata_parser.speed_filter(
            ProjectPath.folder,
            overWrite=args.redo and overWrite_speed_filter_and_linearization,
            phase="cond",
            template=args.phase,
            window_range=2000,
            force=True
            if (args.phase is not None and not show_figures and not args.redo)
            else False,
        )
        rawdata_parser.select_epochs(
            ProjectPath.folder,
            overWrite=(True if (args.redo and args.phase is not None) else False),
            phase="cond",
            force=True if (args.phase is not None and not show_figures) else False,
            find_best_sets=True,
        )
        DataHelper_cond = DataHelperClass(
            ProjectPath.xml,
            mode=mode,
            target=args.target,
            phase="cond",
            nameExp=args.name,
            windowSize=args.window,
            force_ref=False,
            isPredLoss=isPL,
        )
        # adding post test helper
        rawdata_parser.speed_filter(
            ProjectPath.folder,
            overWrite=args.redo and overWrite_speed_filter_and_linearization,
            phase="post",
            template=args.phase,
            window_range=2000,
            force=True
            if (args.phase is not None and not show_figures and not args.redo)
            else False,
        )
        rawdata_parser.select_epochs(
            ProjectPath.folder,
            overWrite=(True if (args.redo and args.phase is not None) else False),
            phase="post",
            force=True if (args.phase is not None and not show_figures) else False,
            find_best_sets=True,
        )
        DataHelper_post = DataHelperClass(
            ProjectPath.xml,
            mode=mode,
            target=args.target,
            phase="post",
            nameExp=args.name,
            windowSize=args.window,
            force_ref=False,
            isPredLoss=isPL,
        )
        helpers = [DataHelper_cond, DataHelper_post, DataHelper]
    for helper in helpers:
        # Create linearization function
        Linearizer = UMazeLinearizer(
            ProjectPath.folder,
            phase=helper.phase,
            data_helper=helper,
            redo=args.redo and overWrite_speed_filter_and_linearization,
        )
        Linearizer.verify_linearization(
            # WARNING: should we use the helper.maxPos() here?
            # as positions are already Aligned/Normalized --> only for viz
            helper.positions / helper.maxPos(),
            ProjectPath.folder,
            overwrite=args.redo and overWrite_speed_filter_and_linearization,
        )

        speedMask = helper.fullBehavior["Times"]["speedFilter"]
        epochMask = inEpochsMask(
            helper.fullBehavior["positionTime"][:, 0],
            helper.fullBehavior["Times"]["trainEpochs"],
        )
        totMask = speedMask * epochMask
        full_training_true_positions = helper.fullBehavior["Positions"][totMask]

        Linearizer.plot_linearization_variable(
            full_training_true_positions / np_max(full_training_true_positions),
            folder=ProjectPath.folder,
            show=show_figures,
            training=True,
        )

        l_function = Linearizer.pykeops_linearization

        # Now that we have the linearization function, we can get the true target
        helper.get_true_target(
            l_function, in_place=True, show=show_figures, speedMask=True
        )

    Parameters = Params(
        helper=DataHelper,
        windowSize=args.window,
        nEpochs=args.epochs,
        phase=args.phase,
        batchSize=(256 if args.window < 0.252 else 128)
        if "1230" not in ProjectPath.xml
        else 64,
        save_json=True,
        isTransformer=not args.lstm,
        transform_w_log=args.transform_w_log,
        denseweight=not args.no_dense,
    )

    # Save ProjectPath object
    save_project_to_pickle(ProjectPath)

    # Training, testing, and preparing network for online setup
    if mode == "bayes":
        from neuroencoders.simpleBayes import decode_bayes as BayesTraining

        try:
            TrainerBayes = BayesTraining.Trainer(
                ProjectPath, phase=args.phase, grid_size=Parameters.GaussianGridSize
            )
            if not os.path.exists(
                os.path.join(TrainerBayes.folderResult, "bayesMatrices.pkl")
            ):
                # Resolve all paths with abspath
                experiment_parent = os.path.abspath(
                    os.path.join(TrainerBayes.projectPath.experimentPath, "..")
                )

                # Source folder path
                source_folder = os.path.abspath(
                    os.path.join(
                        experiment_parent,
                        "bigSigma_GaussianHeatMap_LinearLoss_Transformer",
                    )
                )

                # Target symlink folder path
                last_bayes_folder = os.path.abspath(
                    os.path.join(experiment_parent, "last_bayes")
                )

                # Source file path
                source_file = os.path.join(
                    source_folder, "results", "bayesMatrices.pkl"
                )

                # Target file path
                target_file = os.path.abspath(
                    os.path.join(TrainerBayes.folderResult, "bayesMatrices.pkl")
                )

                if os.path.exists(source_file):
                    # Task 1: Create symlink folder "last_bayes" pointing to the bigSigma folder
                    if not os.path.exists(last_bayes_folder):
                        try:
                            os.symlink(source_folder, last_bayes_folder)
                            print(
                                f"Created symlink folder: {last_bayes_folder} -> {source_folder}"
                            )
                        except OSError as e:
                            print(f"Failed to create symlink folder: {e}")

                    # Task 2: Copy bayesMatrices.pkl from last_bayes/results/ to folderResults/
                    last_bayes_file = os.path.join(
                        last_bayes_folder, "results", "bayesMatrices.pkl"
                    )

                    try:
                        # Ensure target directory exists
                        os.makedirs(os.path.dirname(target_file), exist_ok=True)

                        # Copy the file
                        shutil.copy2(last_bayes_file, target_file)
                        print(
                            f"Copied bayesMatrices.pkl from {last_bayes_file} to {target_file}"
                        )

                    except (OSError, IOError) as e:
                        print(f"Failed to copy file: {e}")
                        # Fallback: try copying directly from source
                        try:
                            shutil.copy2(source_file, target_file)
                            print(
                                f"Fallback: Copied bayesMatrices.pkl directly from {source_file} to {target_file}"
                            )
                        except (OSError, IOError) as e2:
                            print(f"Fallback copy also failed: {e2}")
                else:
                    print(f"Source file not found: {source_file}")

            # Load or create bayesMatrices
            bayesMatrices = TrainerBayes.train_order_by_pos(
                DataHelper.fullBehavior,
                l_function=l_function,
                mutual_info_method=Parameters.mutual_info_method,
                load_last_bayes=False,
                redo=args.redo,
                flat_prior=args.flat_prior,
            )

            # now run the fancy inference
            if (
                not os.path.exists(
                    os.path.join(
                        TrainerBayes.folderResult,
                        str(windowSizeMS),
                        "errorFig_2d_bayes_training_inferring.png",
                    )
                )
                or args.redo
            ):
                print("\nTesting training set")
                timeStepPred = np.squeeze(
                    np.array(
                        pd.read_csv(
                            os.path.join(
                                ProjectPath.folderResult,
                                str(windowSizeMS),
                                "timeStepsPred_training.csv",
                            )
                        ).values[:, 1:],
                        dtype=np.float64,
                    )
                ).flatten()
                outputs = TrainerBayes.test_as_NN(
                    DataHelper.fullBehavior,
                    bayesMatrices,
                    timeStepPred,
                    windowSizeMS=windowSizeMS,
                    useTrain=True,
                    l_function=l_function,
                    phase="training",
                    flat_prior=args.flat_prior,
                )
                print_results.print_results(
                    TrainerBayes.folderResult,
                    typeDec="bayes",
                    results=outputs,
                    windowSizeMS=windowSizeMS,
                    show=show_figures,
                    lossSelection=0.1,
                    euclidean=False,
                    target=args.target,
                    phase="training",
                    force=args.redo,
                    useSpeedMask=True,
                    training_data=TrainerBayes.training_data,
                    l_function=l_function,
                )

            if (
                not os.path.exists(
                    os.path.join(
                        TrainerBayes.folderResult,
                        str(windowSizeMS),
                        f"errorFig_2d_bayes_{args.phase}_inferring.png",
                    )
                )
                or args.redo
            ):
                print("Testing inference set")
                timeStepPred = np.squeeze(
                    np.array(
                        pd.read_csv(
                            os.path.join(
                                ProjectPath.folderResult,
                                str(windowSizeMS),
                                f"timeStepsPred_{args.phase}.csv",
                            )
                        ).values[:, 1:],
                        dtype=np.float64,
                    )
                ).flatten()
                outputs = TrainerBayes.test_as_NN(
                    DataHelper.fullBehavior,
                    bayesMatrices,
                    timeStepPred,
                    windowSizeMS=windowSizeMS,
                    useTrain=False,
                    l_function=l_function,
                    phase=args.phase,
                    flat_prior=args.flat_prior,
                )
                print_results.print_results(
                    TrainerBayes.folderResult,
                    windowSizeMS=windowSizeMS,
                    results=outputs,
                    typeDec="bayes",
                    show=show_figures,
                    lossSelection=0.1,
                    euclidean=False,
                    target=args.target,
                    phase=args.phase,
                    training_data=TrainerBayes.training_data,
                    useSpeedMask=True,
                    l_function=l_function,
                    force=args.redo,
                )

            if (
                not os.path.exists(
                    os.path.join(
                        TrainerBayes.folderResult,
                        str(windowSizeMS),
                        "bayes_featurePred_cond.csv",
                    )
                )
                or args.redo
            ):
                print("Testing conditioning set")
                timeStepPred = np.squeeze(
                    np.array(
                        pd.read_csv(
                            os.path.join(
                                ProjectPath.folderResult,
                                str(windowSizeMS),
                                "timeStepsPred_cond.csv",
                            )
                        ).values[:, 1:],
                        dtype=np.float64,
                    )
                ).flatten()
                outputs = TrainerBayes.test_as_NN(
                    DataHelper_cond.fullBehavior,
                    bayesMatrices,
                    timeStepPred,
                    windowSizeMS=windowSizeMS,
                    useTrain=True,
                    l_function=l_function,
                    phase="cond",
                    flat_prior=args.flat_prior,
                )
                print_results.print_results(
                    TrainerBayes.folderResult,
                    windowSizeMS=windowSizeMS,
                    results=outputs,
                    typeDec="bayes",
                    show=show_figures,
                    lossSelection=0.1,
                    euclidean=False,
                    target=args.target,
                    phase="cond",
                    training_data=TrainerBayes.training_data,
                    useSpeedMask=True,
                    l_function=l_function,
                    force=args.redo,
                )

            if (
                not os.path.exists(
                    os.path.join(
                        TrainerBayes.folderResult,
                        str(windowSizeMS),
                        "bayes_featurePred_post.csv",
                    )
                )
                or args.redo
            ):
                print("Testing post set")
                timeStepPred = np.squeeze(
                    np.array(
                        pd.read_csv(
                            os.path.join(
                                ProjectPath.folderResult,
                                str(windowSizeMS),
                                "timeStepsPred_post.csv",
                            )
                        ).values[:, 1:],
                        dtype=np.float64,
                    )
                ).flatten()
                outputs = TrainerBayes.test_as_NN(
                    DataHelper_post.fullBehavior,
                    bayesMatrices,
                    timeStepPred,
                    windowSizeMS=windowSizeMS,
                    useTrain=True,
                    l_function=l_function,
                    phase="post",
                    flat_prior=args.flat_prior,
                )
                print_results.print_results(
                    TrainerBayes.folderResult,
                    windowSizeMS=windowSizeMS,
                    results=outputs,
                    typeDec="bayes",
                    show=show_figures,
                    lossSelection=0.1,
                    euclidean=False,
                    target=args.target,
                    phase="post",
                    training_data=TrainerBayes.training_data,
                    useSpeedMask=True,
                    l_function=l_function,
                    force=args.redo,
                )
        except FileNotFoundError:
            raise ValueError(
                'To run the bayes mode as NN, you need to run the "NN" trainer first.'
            )

        if args.test_sleep:
            if (
                not os.path.exists(
                    os.path.join(
                        TrainerBayes.folderResultSleep,
                        str(windowSizeMS),
                        "PostSleep",
                        "bayes_featurePred.csv",
                    )
                )
                or args.redo
            ):
                print("Testing sleep set")
                # Test sleep as NN
                outputs_sleep = TrainerBayes.test_sleep_as_NN(
                    DataHelper.fullBehavior,
                    bayesMatrices,
                    windowSizeMS=windowSizeMS,
                    l_function=l_function,
                )

        # Save and create alignment tools
        from neuroencoders.importData.compareSpikeFiltering import WaveFormComparator

        if args.striding is None and args.striding_factor is None:
            raise ValueError(
                "You must provide either a striding (-s) or a striding factor (-sfact) argument."
            )
        strideFactor = (
            int(args.striding_factor)
            if args.striding_factor is not None
            else int(round(args.window / args.striding, 4))
        )
        ### Compare and align trainset waveforms
        WFCTrain = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=True,
            windowSizeMS=windowSizeMS,
            phase=args.phase,
            strideFactor=strideFactor,
        )
        WFCTrain.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )
        ### Compare and align trainset waveforms
        WFCTrainTest = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=True,
            useAll=True,
            windowSizeMS=windowSizeMS,
            phase="training",
            strideFactor=strideFactor,
        )
        WFCTrainTest.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )
        WFCTest = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=False,
            windowSizeMS=windowSizeMS,
            phase=args.phase,
            strideFactor=strideFactor,
        )
        WFCTest.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )

        ### Compare and align conditioning waveforms
        WFCCond = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper_cond.fullBehavior,
            useTrain=True,
            useAll=True,
            windowSizeMS=windowSizeMS,
            phase=args.phase,
            strideFactor=strideFactor,
        )
        WFCCond.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )

        ### Compare and align PostTests waveforms
        WFCPost = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper_post.fullBehavior,
            useTrain=True,
            useAll=True,
            windowSizeMS=windowSizeMS,
            phase=args.phase,
            strideFactor=strideFactor,
        )
        WFCPost.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )
    elif mode == "ann":
        # Create data
        import neuroencoders.importData.juliaData as jD
        from neuroencoders.fullEncoder import an_network as Training
        from neuroencoders.importData.juliaData.julia_data_parser import (
            julia_spike_filter,
        )
        from neuroencoders.openEphysExport.generate_json import generate_json

        folderCode = os.path.dirname(jD.__file__) + os.path.sep

        if args.striding is None and args.striding_factor is None:
            raise ValueError(
                "You must provide either a striding (-s) or a striding factor (-sfact) argument."
            )

        if args.striding_factor is None:
            windowStride = args.striding
            strideFactor = round(args.window / windowStride, 4)
            # check if windowStride is an integer, if not raise an error
            if not strideFactor.is_integer():
                raise ValueError(
                    f"The {args.windows}ms window size is not compatible with the {args.striding}ms stride."
                )
        else:
            strideFactor = args.striding_factor
            windowStride = round(args.window / strideFactor, 4)
            if windowStride < 0.036:
                warn(
                    f"The selected striding factor of {strideFactor} is too high for the selected window size of {windowStride}ms. Setting striding to 36ms."
                )
                windowStride = 0.036
            # check if windowStride is a valid ms value, if not raise an error
            if not (1000 * windowStride).is_integer():
                raise ValueError(
                    f"The {args.windows}ms window size is not compatible with the {strideFactor} striding factor."
                )
        strideFactor = int(strideFactor)

        julia_spike_filter(
            ProjectPath,
            folderCode,
            windowSize=args.window,
            windowStride=windowStride,  # This way the striding is always 36ms-based
            redo=False,
            BUFFERSIZE=216000,
        )

        # Network
        NNTrainer = Training.LSTMandSpikeNetwork(
            ProjectPath,
            Parameters,
            deviceName=deviceName,
            debug=debug,
            phase=args.phase,
            isTransformer=Parameters.isTransformer,
            verbose=True,
            behaviorData=DataHelper.fullBehavior,
            alpha=Parameters.denseweightAlpha,
            linearizer=Linearizer,
        )

        if (
            not os.path.exists(
                os.path.join(
                    NNTrainer.folderResult,
                    str(windowSizeMS),
                    "featurePred_training.csv",
                )
            )
            or args.redo
        ):
            NNTrainer.train(
                DataHelper.fullBehavior,
                windowSizeMS=windowSizeMS,
                isPredLoss=isPL,
                earlyStop=args.early_stop,
                load_model=True,
                fine_tune=True,
                l_function=l_function,
                num_augmentations=11 if args.window < 0.504 else 6,
                strideFactor=strideFactor,
            )
            T = None

        if Parameters.GaussianHeatmap:
            print("Will now run temperature scaling for gaussian heatmap")
            T = NNTrainer.test(
                DataHelper.fullBehavior,
                fit_temperature=True,
                epochKey="trainEpochs",
                windowSizeMS=windowSizeMS,
                useSpeedFilter=True,
                isPredLoss=isPL,
                strideFactor=strideFactor,
            )
        # now run the fancy inference
        if (
            not os.path.exists(
                os.path.join(
                    NNTrainer.folderResult,
                    str(windowSizeMS),
                    "errorFig_2d_NN_training_inferring.png",
                )
            )
            or args.redo
        ):
            print("Testing training set")
            NNTrainer.test(
                DataHelper.fullBehavior,
                windowSizeMS=windowSizeMS,
                isPredLoss=isPL,
                l_function=l_function,
                useSpeedFilter=False,
                phase="training",
                useTrain=True,
                template=args.phase,
                T_scaling=T,
                strideFactor=strideFactor,
            )
            print_results.print_results(
                NNTrainer.folderResult,
                windowSizeMS=windowSizeMS,
                show=show_figures,
                lossSelection=0.5,
                euclidean=False,
                target=args.target,
                phase="training",
                useSpeedMask=True,
                training_data=NNTrainer.training_data,
                force=args.redo,
                l_function=l_function,
            )

        if (
            not os.path.exists(
                os.path.join(
                    NNTrainer.folderResult,
                    str(windowSizeMS),
                    f"errorFig_2d_NN_{args.phase}_inferring.png",
                )
            )
            or args.redo
        ):
            print("Testing inference set")
            NNTrainer.test(
                DataHelper.fullBehavior,
                windowSizeMS=windowSizeMS,
                isPredLoss=isPL,
                l_function=l_function,
                useSpeedFilter=False,
                phase=args.phase,
                useTrain=False,
                template=args.phase,
                T_scaling=T,
                strideFactor=strideFactor,
            )
            print_results.print_results(
                NNTrainer.folderResult,
                windowSizeMS=windowSizeMS,
                show=show_figures,
                lossSelection=0.5,
                euclidean=False,
                force=args.redo,
                target=args.target,
                phase=args.phase,
                training_data=NNTrainer.training_data,
                useSpeedMask=True,
                l_function=l_function,
            )

        if (
            not os.path.exists(
                os.path.join(
                    NNTrainer.folderResult,
                    str(windowSizeMS),
                    "featurePred_cond.csv",
                )
            )
            or args.redo
        ):
            print("Testing conditioning set")
            NNTrainer.test(
                DataHelper_cond.fullBehavior,
                windowSizeMS=windowSizeMS,
                isPredLoss=isPL,
                l_function=l_function,
                useSpeedFilter=False,
                phase="cond",
                useTrain=True,
                T_scaling=T,
                strideFactor=strideFactor,
            )

            print_results.print_results(
                NNTrainer.folderResult,
                windowSizeMS=windowSizeMS,
                show=show_figures,
                lossSelection=0.5,
                euclidean=False,
                target=args.target,
                phase="cond",
                training_data=NNTrainer.training_data,
                useSpeedMask=True,
                l_function=l_function,
                force=args.redo,
            )

        if (
            not os.path.exists(
                os.path.join(
                    NNTrainer.folderResult,
                    str(windowSizeMS),
                    "featurePred_post.csv",
                )
            )
            or args.redo
        ):
            print("Testing PostTest set")
            NNTrainer.test(
                DataHelper_post.fullBehavior,
                windowSizeMS=windowSizeMS,
                isPredLoss=isPL,
                l_function=l_function,
                useSpeedFilter=False,
                phase="post",
                useTrain=True,
                T_scaling=T,
                strideFactor=strideFactor,
            )

            print_results.print_results(
                NNTrainer.folderResult,
                windowSizeMS=windowSizeMS,
                show=show_figures,
                lossSelection=0.5,
                euclidean=False,
                target=args.target,
                phase="post",
                training_data=NNTrainer.training_data,
                useSpeedMask=True,
                l_function=l_function,
                force=args.redo,
            )

        if args.test_sleep and (
            not os.path.exists(
                os.path.join(
                    NNTrainer.folderResultSleep,
                    str(windowSizeMS),
                    "PostSleep",
                    "featurePred.csv",
                )
            )
            or args.redo
        ):
            NNTrainer.testSleep(
                behaviorData=DataHelper.fullBehavior,
                l_function=l_function,
                windowSizeMS=windowSizeMS,
                isPredLoss=isPL,
                strideFactor=strideFactor,
                T_scaling=T,
                # TODO: add windowSizeDecoder --> decode small windows with big window trained model
            )

        NNTrainer.clear_session()

        # Create json
        if isPL:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "predLossModel",
            )
        else:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "fullModel",
            )
        # WARNING: for now modelPath is not used due to issues in the generate_json function.
        # Indeed the generate & load from json (see Decoder class) already look for the str(window), savedModels...
        # Will use NNTrainer.folderModels instead
        print(ProjectPath.json)
        generate_json(ProjectPath, NNTrainer.folderModels, DataHelper.list_channels)
        print("Saved json file for Julia thresholds and checkpoints.")

    elif mode == "decode":
        from neuroencoders.decoder import decode
        from neuroencoders.importData.juliaData.julia_data_parser import (
            julia_spike_filter,
        )

        if not os.path.isfile(ProjectPath.json):
            sys.exit(
                "No .json file was found to pick up the network to decode."
                + " Please verify that you encoded the weights, and that "
                + "you json file has the same name as basefile.dat"
            )
        else:
            # Create data
            folderCode = os.path.dirname(os.path.realpath(__file__)) + os.path.sep
            # Right now, the thresholds are not the same
            windowStride = args.striding
            strideFactor = round(args.window / windowStride, 4)
            # check if windowStride is an integer, if not raise an error
            if not strideFactor.is_integer():
                raise ValueError(
                    "The window size is not compatible with the 36ms stride."
                )
            julia_spike_filter(
                ProjectPath,
                folderCode,
                windowSize=args.window,
                windowStride=windowStride,  # This way the striding is always 36ms-based
            )
            # Decode
            Decoder = decode.Decoder(
                ProjectPath,
                Parameters,
                windowSizeMS=windowSizeMS,
                deviceName=deviceName,
            )
            outputs = Decoder.test(
                DataHelper.fullBehavior,
                l_function=l_function,
                windowSizeMS=windowSizeMS,
            )
            print_results.print_results(Decoder.folderResult, windowSizeMS=windowSizeMS)

    elif mode == "compare":
        from neuroencoders.fullEncoder import an_network as Training
        from neuroencoders.importData.compareSpikeFiltering import WaveFormComparator
        from neuroencoders.importData.juliaData.julia_data_parser import (
            julia_spike_filter,
        )
        from neuroencoders.openEphysExport.generate_json import generate_json
        from neuroencoders.resultAnalysis import paper_figures
        from neuroencoders.simpleBayes import decode_bayes as BayesTrainer

        ### Bayes
        TrainerBayes = BayesTrainer.Trainer(ProjectPath)
        bayesMatrices = TrainerBayes.train_order_by_pos(
            DataHelper.fullBehavior, l_function=l_function
        )

        ### ANN TODO: if exists
        folderCode = os.path.dirname(os.path.realpath(__file__)) + os.path.sep
        julia_spike_filter(
            ProjectPath,
            folderCode,
            windowSize=args.window,
            windowStride=windowStride,  # This way the striding is always 36ms-based
            redo=False,
            BUFFERSIZE=144000,
        )
        # Network
        NNTrainer = Training.LSTMandSpikeNetwork(
            ProjectPath,
            Parameters,
            deviceName=deviceName,
            debug=debug,
        )
        NNTrainer.fix_linearizer(Linearizer.mazePoints, Linearizer.tsProj)
        NNTrainer.train(DataHelper.fullBehavior, windowSizeMS=windowSizeMS)
        NNTrainer.test(
            DataHelper.fullBehavior, l_function=l_function, windowSizeMS=windowSizeMS
        )
        if isPL:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "predLossModel.keras",
            )
        else:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "fullModel.keras",
            )
        generate_json(ProjectPath, modelPath, DataHelper.list_channels)

        ### Compare and align waveforms
        WFCTrain = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=True,
            windowSizeMS=windowSizeMS,
            phase=args.phase,
        )
        WFCTrain.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )
        WFCTest = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=False,
            windowSizeMS=windowSizeMS,
            phase=args.phase,
        )
        WFCTest.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )

        ### Figures
        figures = paper_figures.PaperFigures(
            ProjectPath,
            DataHelper.fullBehavior,
            TrainerBayes,
            l_function,
            bayesMatrices=bayesMatrices,
            phase=args.phase,
        )
        figures.load_data()
        figures.load_bayes()
        figures.fig_example_linear(block=False)
        figures.hist_linerrors(block=False, speed="fast")
        figures.nnVSbayes(block=False, speed="fast")
        figures.predLoss_vs_trueLoss(block=False, speed="fast")
        figures.fig_example_2d(block=False, speed="fast")
        figures.predLoss_linError(block=False, speed="fast")
        figures.predLoss_euclError(block=False, speed="fast")
        figures.fig_example_linear_filtered(block=False)


if __name__ == "__main__":
    print()
    import argparse

    Parser = argparse.ArgumentParser(
        description="Creating and training an agent "
        + "to decode high level features from electrophysiology data."
    )
    subparsers = Parser.add_subparsers(
        dest="mode",
        title="modes",
        description="all existing modes of encoding",
        help="selects an encoding mode"
        + ". For more information type the mode name between neuroencoder and -h",
    )

    for cmd in ["ann", "bayes", "compare", "decode"]:
        p = subparsers.add_parser(cmd)
        p.add_argument("path", help="path to xml file", type=os.path.abspath)
        if cmd == "decode":
            p.add_argument("jsonPath", type=str, help="path to json file")
        p.add_argument(
            "-w",
            "--window",
            type=float,
            help="defines window size, in seconds. Defaults to 0.108",
            default=0.108,
        )
        p.add_argument(
            "-n",
            "--name",
            type=str,
            help="name of the folder where all models and results will be stored",
            default="Current_results",
        )

        p.add_argument(
            "-e",
            "--epochs",
            type=int,
            help="number of epochs for training. Defaults to 100",
            default=100,
        )

        p.add_argument(
            "-p",
            "--phase",
            type=str,
            help="Use only one phase of experiments for training/selectioning the epochs. Will overwrite the epochs",
            choices=[
                "all",
                "pre",
                "hab",
                "preNoHab",
                "cond",
                "post",
                "extinction",
                "postNoExtinction",
            ],
            default=None,
        )

        p.add_argument(
            "-r",
            "--redo",
            action="store_true",
            help="Force and redo all the parameters settings (speed filter, epochs selection, etc.)",
        )
        p.add_argument(
            "-t",
            "--target",
            type=str,
            help="name of feature to be decoded. Defaults are Xtsd and Ytsd. "
            + "Must be a tsd variable from behavResources.mat",
            default="pos",
            choices=[
                "pos",
                "lin",
                "linear",
                "LinAndThigmo",
                "linAndThigmo",
                "LinAndDirection",
                "Direction",
                "direction",
                "linandheaddirection",
                "linandspeed",
                "PosAndDirection",
                "Posandheaddirection",
                "Posandspeed",
                "Posandheaddirectionandspeed",
                "PosAndHeadDirectionAndThigmo",
                "PosAndDirectionAndThigmo",
            ],
        )
        p.add_argument(
            "-lstm",
            "--lstm",
            action="store_true",
            help="defines whether to use a lstm network instead of transformer",
        )
        p.add_argument(
            "-log",
            "--transform_w_log",
            action="store_true",
            help="defines whether the uncertainty loss is majored with a log function or stays euclidian",
        )
        p.add_argument(
            "-nod",
            "--no-dense",
            action="store_true",
            help="defines whether the dense weight loss should be used or not",
        )

        p.add_argument(
            "-sleep",
            "--test_sleep",
            action="store_true",
            help="defines whether to test the decoder on the Pre and Post sleep phases",
        )
        p.add_argument(
            "-s",
            "--striding",
            type=float,
            help="defines the striding of the window, in seconds. Defaults to None",
            default=None,
        )
        # add optional argument to select striding factor instead of striding and override striding
        p.add_argument(
            "-sfact",
            "--striding_factor",
            type=int,
            help="defines the striding factor of the window. "
            + "If selected, overrides the striding argument. "
            + "Defaults to None",
            default=None,
        )
        p.add_argument(
            "-fp",
            "--flat_prior",
            action="store_true",
            help="defines whether to use a flat prior for bayesian decoding",
        )

        if cmd != "bayes":
            p.add_argument(
                "-g",
                "--gpu",
                action="store_true",
                help="run computations on gpu. Requires specific installation.",
            )
            p.add_argument(
                "-pl",
                "--predicted_loss",
                action="store_true",
                help="defines whether another, predLoss only, "
                + "network will be trained on the piece of data",
            )
            p.add_argument(
                "-es",
                "--early_stop",
                action="store_true",
                help="defines whether to use early stopping during training",
            )

    args = Parser.parse_args()

    print()
    import shutil

    rows, columns = shutil.get_terminal_size()
    print("|| neuroEncoder by MOBS ||".center(rows))
    print("may 2020 - march 2022".center(rows))
    print("email: t.balenbois@gmail.com && bryzgalovdm@gmail.com".center(rows))
    print()
    print()
    print("{:=^40}".format("PARAMETERS").center(rows))
    for k, v in vars(args).items():
        print(f"{k}: {v}".center(rows))
    print("{:=^40}".format("END").center(rows))

    # TODO:  Check if split is not too optimistic
    if args.mode == "decode":
        print("Decoding of full dataset \n")

    if not (
        os.path.isfile(
            os.path.abspath(
                os.path.expanduser(
                    os.path.split(args.path)[0] + os.path.sep + "nnBehavior.mat"
                )
            )
        )
    ):
        # Get the tsd feature, i.e. a nnBehavior.mat file from the tsd feature.
        # The target is the name of the feature to be decoded, will default to the position.
        subprocess.run(
            [
                os.path.join(os.path.dirname(__file__), "getTsdFeature.sh"),
                os.path.abspath(os.path.expanduser(args.path.strip("'"))),
                "'" + args.target + "'",
            ]
        )
    if not (
        os.path.isfile(
            os.path.abspath(
                os.path.expanduser(
                    os.path.split(args.path)[0]
                    + os.path.sep
                    + "optional_nnBehavior.mat"
                )
            )
        )
    ):
        # Get the tsd feature, i.e. a nnBehavior.mat file from the tsd feature.
        # The target is the name of the feature to be decoded, will default to the position.
        subprocess.run(
            [
                os.path.join(os.path.dirname(__file__), "addTsdFeature.sh"),
                os.path.abspath(os.path.expanduser(args.path.strip("'"))),
                "'" + args.target + "'",
            ]
        )
    print()

    main(args)

    print()
    print()
    print("Algo has done what it wanted to do.")
