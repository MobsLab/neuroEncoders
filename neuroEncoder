#!/usr/bin/env python
# neuroEncoder by the Memory, Oscillations and Brain States (MOBS) team
# 2017-2024
# by Thibault Balenbois, Pierre Orhan, Dmitri Bryzgalov and Th√©otime de Charrin
# t.balenbois@gmail.com; brygalovdm@gmail.com; theotime.decharrin@gmail.com

import os
import subprocess

# Load standard libs
import sys
from warnings import warn

from utils.global_classes import DataHelper as DataHelperClass

# Load custom code
from utils.global_classes import Params, Project, save_project_to_pickle

# Meta parameters
show_figures = False
debug = True


def main(args):
    # WARNING: This is a very long function, consider splitting it?
    # NOTE: The "nnBehavior.mat" file is already created when executing main func see `getTsdFeature.sh`.
    # Manage inputs
    if not args.mode == "bayes":
        if args.gpu:
            from utils import management

            deviceName = management.manage_devices("GPU")
        else:
            os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
            os.environ["CUDA_VISIBLE_DEVICES"] = ""
            from utils import management

            deviceName = management.manage_devices("CPU")
    if args.mode == "decode":
        jsonPath = os.path.expanduser(args.jsonPath)
    else:
        jsonPath = None

    from importData import rawdata_parser
    from resultAnalysis import print_results
    from transformData.linearizer import UMazeLinearizer

    # Output to shell
    print()
    if not args.mode == "bayes":
        print("NEUROENCODER: DEVICE", deviceName)
    xmlPath = args.path.strip("'")
    print("NEUROENCODER: PATH", xmlPath)
    # WARNING: windowSize is in s and gets converted to ms
    windowSizeMS = int(args.window * 1000)
    print(f"NEUROENCODER: WINDOW {windowSizeMS} ms")
    mode = args.mode
    print("NEUROENCODER: MODE", mode)
    if mode != "bayes":
        isPL = args.predicted_loss
        if isPL:
            print(
                "Two networks will be tested: one full on training set and "
                "one with predLoss only on a separate part of data"
            )
    else:
        isPL = False
    print()

    # Get behavior and tune parameters
    ProjectPath = Project(
        os.path.expanduser(xmlPath),
        jsonPath=jsonPath,
        nameExp=args.name,
        windowSize=args.window,
    )
    # Select the data for testing
    if mode != "decode":
        try:
            rawdata_parser.speed_filter(
                ProjectPath.folder,
                overWrite=(True if args.redo else False),
                phase=args.phase,
            )
        except Exception as e:
            # If an IndexError occurs, it means that the speed filter failed
            print(f"Error during speed filter: {e}")
            args.phase = None
            rawdata_parser.speed_filter(
                ProjectPath.folder,
                overWrite=(True if args.redo else False),
                phase=args.phase,
            )
            warn(
                f'"IndexError" occurred for {ProjectPath.folder}, setting phase to None.'
            )
        rawdata_parser.select_epochs(
            ProjectPath.folder,
            overWrite=(True if (args.redo or args.phase is not None) else False),
            phase=args.phase,
            force=True if (args.phase is not None and not show_figures) else False,
            find_best_sets=True,
            isPredLoss=isPL,
        )
    # Create parameters
    DataHelper = DataHelperClass(
        ProjectPath.xml,
        mode=mode,
        target=args.target,
        phase=args.phase,
        nameExp=args.name,
        windowSize=args.window,
    )
    # Create linearization function
    Linearizer = UMazeLinearizer(ProjectPath.folder, phase=args.phase)
    Linearizer.verify_linearization(
        DataHelper.positions / DataHelper.maxPos(),
        ProjectPath.folder,
        overwrite=(True if args.redo else False),
    )
    l_function = Linearizer.pykeops_linearization

    # Now that we have the linearization function, we can get the true target
    DataHelper.get_true_target(l_function, in_place=True, show=show_figures)

    Parameters = Params(
        helper=DataHelper,
        windowSize=args.window,
        nEpochs=args.epochs,
        phase=args.phase,
        batchSize=256 if args.window < 1.08 else 128,
        save_json=True,
    )

    # Save ProjectPath object
    save_project_to_pickle(ProjectPath)
    # Save main parameters in json file in the Params.folder
    # save_project_to_pickle(
    #     Parameters, output=os.path.join(Parameters.resultsPath, "Parameters.pkl")
    # )

    # Training, testing, and preparing network for online setup
    if mode == "bayes":
        from simpleBayes import decode_bayes as Training

        TrainerBayes = Training.Trainer(ProjectPath, phase=args.phase)
        bayesMatrices = TrainerBayes.train_order_by_pos(
            DataHelper.fullBehavior, l_function=l_function
        )
        # WARNING: Why does this function not exist in the class?
        # TODO: Fix this if Bayes is still of actuality
        try:
            import numpy as np
            import pandas as pd

            if args.phase is not None:
                suffix = f"_{args.phase}"
            else:
                suffix = ""
            timeStepPred = np.squeeze(
                np.array(
                    pd.read_csv(
                        os.path.join(
                            ProjectPath.folderResult,
                            str(windowSizeMS),
                            f"timeStepsPred{suffix}.csv",
                        )
                    ).values[:, 1:],
                    dtype=np.float32,
                )
            )
        except FileNotFoundError:
            raise ValueError(
                'To run the bayes mode as NN, you need to run the "NN" trainer first.'
            )

        outputs = TrainerBayes.test_as_NN(
            DataHelper.fullBehavior,
            bayesMatrices,
            timeStepPred,
            windowSizeMS=windowSizeMS,
            useTrain=False,
            l_function=l_function,
        )
        print_results.print_results(
            TrainerBayes.folderResult,
            typeDec="bayes",
            results=outputs,
            windowSizeMS=windowSizeMS,
            show=show_figures,
            lossSelection=0.1,
            euclidean=False,
            target=args.target,
            phase=args.phase,
            force=args.redo,
        )

    elif mode == "ann":
        from fullEncoder import an_network as Training
        from importData.juliaData.julia_data_parser import julia_spike_filter
        from openEphysExport.generate_json import generate_json

        # Create data
        folderCode = os.path.dirname(os.path.realpath(__file__)) + os.path.sep
        windowStride = args.striding
        strideFactor = round(args.window / windowStride, 4)
        # check if windowStride is an integer, if not raise an error
        if not strideFactor.is_integer():
            raise ValueError("The window size is not compatible with the 36ms stride.")
        julia_spike_filter(
            ProjectPath,
            folderCode,
            windowSize=args.window,
            windowStride=windowStride,  # This way the striding is always 36ms-based
            redo=False,
            BUFFERSIZE=144000,
        )
        # Network
        # return
        NNTrainer = Training.LSTMandSpikeNetwork(
            ProjectPath,
            Parameters,
            deviceName=deviceName,
            debug=debug,
            phase=args.phase,
            isTransformer=Parameters.isTransformer,
        )
        NNTrainer.fix_linearizer(Linearizer.mazePoints, Linearizer.tsProj)
        # TODO: if target is not position, change the target

        NNTrainer.train(
            DataHelper.fullBehavior,
            windowSizeMS=windowSizeMS,
            isPredLoss=isPL,
            earlyStop=args.early_stop,
            # load_model=True,
        )

        NNTrainer.test(
            DataHelper.fullBehavior,
            l_function=l_function,
            windowSizeMS=windowSizeMS,
            isPredLoss=isPL,
            useSpeedFilter=False,
            phase=args.phase,
            useTrain=False,
            template=args.phase,
        )

        print_results.print_results(
            NNTrainer.folderResult,
            windowSizeMS=windowSizeMS,
            show=show_figures,
            lossSelection=0.1,
            euclidean=False,
            target=args.target,
            phase=args.phase,
        )
        NNTrainer.clear_session()
        # Create json
        if isPL:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "predLossModel",
            )
        else:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "fullModel",
            )
        # WARNING: for now modelPath is not used due to issues in the generate_json function.
        # Indeed the generate & load from json (see Decoder class) already look for the str(window), savedModels...
        # Will use NNTrainer.folderModels instead
        print(ProjectPath.json)
        generate_json(ProjectPath, NNTrainer.folderModels, DataHelper.list_channels)
        print("Saved json file for Julia thresholds and checkpoints.")

    elif mode == "decode":
        from decoder import decode
        from importData.juliaData.julia_data_parser import julia_spike_filter

        if not os.path.isfile(ProjectPath.json):
            sys.exit(
                "No .json file was found to pick up the network to decode."
                + " Please verify that you encoded the weights, and that "
                + "you json file has the same name as basefile.dat"
            )
        else:
            # Create data
            folderCode = os.path.dirname(os.path.realpath(__file__)) + os.path.sep
            # Right now, the thresholds are not the same
            windowStride = args.striding
            strideFactor = round(args.window / windowStride, 4)
            # check if windowStride is an integer, if not raise an error
            if not strideFactor.is_integer():
                raise ValueError(
                    "The window size is not compatible with the 36ms stride."
                )
            julia_spike_filter(
                ProjectPath,
                folderCode,
                windowSize=args.window,
                windowStride=windowStride,  # This way the striding is always 36ms-based
            )
            # Decode
            Decoder = decode.Decoder(
                ProjectPath,
                Parameters,
                windowSizeMS=windowSizeMS,
                deviceName=deviceName,
            )
            outputs = Decoder.test(
                DataHelper.fullBehavior,
                l_function=l_function,
                windowSizeMS=windowSizeMS,
            )
            print_results.print_results(Decoder.folderResult, windowSizeMS=windowSizeMS)

    elif mode == "compare":
        from fullEncoder import an_network as Training
        from importData.compareSpikeFiltering import WaveFormComparator
        from importData.juliaData.julia_data_parser import julia_spike_filter
        from openEphysExport.generate_json import generate_json
        from resultAnalysis import paper_figures
        from simpleBayes import decode_bayes as BayesTrainer

        ### Bayes
        TrainerBayes = BayesTrainer.Trainer(ProjectPath)
        bayesMatrices = TrainerBayes.train_order_by_pos(
            DataHelper.fullBehavior, l_function=l_function
        )

        ### ANN TODO: if exists
        folderCode = os.path.dirname(os.path.realpath(__file__)) + os.path.sep
        julia_spike_filter(
            ProjectPath,
            folderCode,
            windowSize=args.window,
            windowStride=windowStride,  # This way the striding is always 36ms-based
            redo=False,
            BUFFERSIZE=144000,
        )
        # Network
        NNTrainer = Training.LSTMandSpikeNetwork(
            ProjectPath,
            Parameters,
            deviceName=deviceName,
            debug=debug,
        )
        NNTrainer.fix_linearizer(Linearizer.mazePoints, Linearizer.tsProj)
        NNTrainer.train(DataHelper.fullBehavior, windowSizeMS=windowSizeMS)
        NNTrainer.test(
            DataHelper.fullBehavior, l_function=l_function, windowSizeMS=windowSizeMS
        )
        if isPL:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "predLossModel.keras",
            )
        else:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "fullModel.keras",
            )
        generate_json(ProjectPath, modelPath, DataHelper.list_channels)

        ### Compare and align waveforms
        WFCTrain = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=True,
            windowSizeMS=windowSizeMS,
        )
        WFCTrain.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )
        WFCTest = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=False,
            windowSizeMS=windowSizeMS,
        )
        WFCTest.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )

        ### Figures
        figures = paper_figures.PaperFigures(
            ProjectPath,
            DataHelper.fullBehavior,
            TrainerBayes,
            l_function,
            bayesMatrices=bayesMatrices,
        )
        figures.load_data()
        figures.test_bayes()
        figures.fig_example_linear()
        figures.hist_linerrors()
        figures.nnVSbayes()
        figures.predLoss_vs_trueLoss()
        figures.fig_example_2d()
        figures.predLoss_linError()
        figures.predLoss_linError()
        figures.fig_example_linear_filtered()


if __name__ == "__main__":
    print()
    import argparse

    Parser = argparse.ArgumentParser(
        description="Creating and training an agent "
        + "to decode high level features from electrophysiology data."
    )
    subparsers = Parser.add_subparsers(
        dest="mode",
        title="modes",
        description="all existing modes of encoding",
        help="selects an encoding mode"
        + ". For more information type the mode name between neuroencoder and -h",
    )

    for cmd in ["ann", "bayes", "compare", "decode"]:
        p = subparsers.add_parser(cmd)
        p.add_argument("path", help="path to xml file", type=os.path.abspath)
        if cmd == "decode":
            p.add_argument("jsonPath", type=str, help="path to json file")
        p.add_argument(
            "-w",
            "--window",
            type=float,
            help="defines window size, in seconds. Defaults to 0.108",
            default=0.108,
        )
        p.add_argument(
            "-n",
            "--name",
            type=str,
            help="name of the folder where all models and results will be stored",
            default="Current_results",
        )

        p.add_argument(
            "-e",
            "--epochs",
            type=int,
            help="number of epochs for training. Defaults to 100",
            default=100,
        )

        p.add_argument(
            "-p",
            "--phase",
            type=str,
            help="Use only one phase of experiments for training/selectioning the epochs. Will overwrite the epochs",
            choices=[
                "all",
                "pre",
                "hab",
                "preNoHab",
                "cond",
                "post",
                "extinction",
                "postNoExtinction",
            ],
            default=None,
        )

        p.add_argument(
            "-r",
            "--redo",
            action="store_true",
            help="Force and redo all the parameters settings (speed filter, epochs selection, etc.)",
        )
        p.add_argument(
            "-t",
            "--target",
            type=str,
            help="name of feature to be decoded. Defaults are Xtsd and Ytsd. "
            + "Must be a tsd variable from behavResources.mat",
            default="pos",
            choices=[
                "pos",
                "lin",
                "linear",
                "LinAndThigmo",
                "linAndThigmo",
                "LinAndDirection",
                "Direction",
                "direction",
            ],
        )

        if cmd != "bayes":
            p.add_argument(
                "-g",
                "--gpu",
                action="store_true",
                help="run computations on gpu. Requires specific installation.",
            )
            p.add_argument(
                "-pl",
                "--predicted_loss",
                action="store_true",
                help="defines whether another, predLoss only, "
                + "network will be train on the piece of data",
            )
            p.add_argument(
                "-s",
                "--striding",
                type=float,
                help="defines the striding of the window, in seconds. Defaults to 0.036",
                default=0.036,
            )
            p.add_argument(
                "-es",
                "--early_stop",
                action="store_true",
                help="defines whether to use early stopping during training",
            )
    args = Parser.parse_args()

    print()
    import shutil

    rows, columns = shutil.get_terminal_size()
    print("|| neuroEncoder by MOBS ||".center(rows))
    print("may 2020 - march 2022".center(rows))
    print("email: t.balenbois@gmail.com && bryzgalovdm@gmail.com".center(rows))
    print()
    print()
    print("{:=^40}".format("PARAMETERS").center(rows))
    for k, v in vars(args).items():
        print(f"{k}: {v}".center(rows))
    print("{:=^40}".format("END").center(rows))

    # TODO:  Check if split is not too optimistic
    if args.mode == "decode":
        print("Decoding of full dataset \n")

    if not (
        os.path.isfile(
            os.path.abspath(
                os.path.expanduser(
                    os.path.split(args.path)[0] + os.path.sep + "nnBehavior.mat"
                )
            )
        )
    ):
        # Get the tsd feature, i.e. a nnBehavior.mat file from the tsd feature.
        # The target is the name of the feature to be decoded, will default to the position.
        subprocess.run(
            [
                os.path.join(os.path.dirname(__file__), "getTsdFeature.sh"),
                os.path.abspath(os.path.expanduser(args.path.strip("'"))),
                "'" + args.target + "'",
            ]
        )
    print()

    main(args)

    print()
    print()
    print("Algo has done what it wanted to do.")
