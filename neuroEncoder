#!/usr/bin/env python
# neuroEncoder by the Memory, Oscillations and Brain States (MOBS) team
# 2017-2024
# by Thibault Balenbois, Pierre Orhan, Dmitri Bryzgalov and Th√©otime de Charrin
# t.balenbois@gmail.com; brygalovdm@gmail.com; theotime.decharrin@gmail.com

import os
import subprocess

# Load standard libs
import sys

# Load custom code
from utils.global_classes import Params, Project


def main(args):
    # WARNING: This is a very long function, consider splitting it?
    # NOTE: The "nnBehavior.mat" file is already created when executing main func see `getTsdFeature.sh`.
    # Manage inputs
    if not args.mode == "bayes":
        if args.gpu:
            from utils import management

            deviceName = management.manage_devices("GPU")
        else:
            os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
            os.environ["CUDA_VISIBLE_DEVICES"] = ""
            from utils import management

            deviceName = management.manage_devices("CPU")
    if args.mode == "decode":
        jsonPath = os.path.expanduser(args.jsonPath)
    else:
        jsonPath = None

    from importData import rawdata_parser
    from resultAnalysis import print_results
    from transformData.linearizer import UMazeLinearizer

    # Output to shell
    print()
    if not args.mode == "bayes":
        print("NEUROENCODER: DEVICE", deviceName)
    xmlPath = args.path.strip("'")
    print("NEUROENCODER: PATH", xmlPath)
    # WARNING: windowSize is in s and gets converted to ms
    windowSizeMS = int(args.window * 1000)
    print(f"NEUROENCODER: WINDOW {windowSizeMS} ms")
    mode = args.mode
    print("NEUROENCODER: MODE", mode)
    if mode != "bayes":
        isPL = args.predicted_loss
        if isPL:
            print(
                "Two networks will be tested: one full on training set and "
                "one with predLoss only on a separate part of data"
            )
    print()

    # Get behavior and tune parameters
    ProjectPath = Project(
        os.path.expanduser(xmlPath),
        jsonPath=jsonPath,
        nameExp=args.name,
        windowSize=args.window,
    )
    # Select the data for testing
    if mode != "decode":
        rawdata_parser.speed_filter(ProjectPath.folder, overWrite=False)
        rawdata_parser.select_epochs(ProjectPath.folder, overWrite=False)
    # Create parameters
    DataHelper = rawdata_parser.DataHelper(ProjectPath, mode)
    Parameters = Params(
        helper=DataHelper,
        windowSize=args.window,
        nEpochs=args.epochs if args.epochs else 100,
    )
    # Create linearization function
    Linearizer = UMazeLinearizer(ProjectPath.folder)
    Linearizer.verify_linearization(
        DataHelper.positions / DataHelper.maxPos(), ProjectPath.folder, overwrite=False
    )
    l_function = Linearizer.pykeops_linearization

    # Save main parameters in json file in the Params.folder
    Parameters.save_params_to_json()

    # Training, testing, and preparing network for online setup
    if mode == "bayes":
        from simpleBayes import decode_bayes as Training
        from importData.epochs_management import inEpochs

        TrainerBayes = Training.Trainer(ProjectPath)
        bayesMatrices = TrainerBayes.train_order_by_pos(
            DataHelper.fullBehavior, l_function
        )
        # WARNING: Why does this function not exist in the class?
        # TODO: Fix this if Bayes is still of actuality
        # timeStepPred = DataHelper.fullBehavior["positionTime"][
        #         inEpochs(
        #             DataHelper.fullBehavior["positionTime"][:, 0],
        #             DataHelper.fullBehavior["Times"]["testEpochs"]
        #         )
        #     ]
        #
        # outputsNN = TrainerBayes.test_as_NN(
        #     DataHelper.fullBehavior, bayesMatrices, timeStepPred, windowSizeMS=windowSize
        # )
        #
        outputs = TrainerBayes.test_legacy(
            bayesMatrices, DataHelper.fullBehavior, windowSizeMS=windowSizeMS
        )
        print_results.print_results(
            TrainerBayes.folderResult,
            typeDec="bayes",
            results=outputs,
            windowSizeMS=windowSizeMS,
        )

    elif mode == "ann":
        from fullEncoder import an_network as Training
        from importData.juliaData.julia_data_parser import julia_spike_filter
        from openEphysExport.generate_json import generate_json

        # Create data
        folderCode = os.path.dirname(os.path.realpath(__file__)) + os.path.sep
        julia_spike_filter(ProjectPath, folderCode, windowSize=args.window)
        # Network
        # let's try with a transformer
        NNTrainer = Training.LSTMandSpikeNetwork(
            ProjectPath, Parameters, deviceName=deviceName
        )
        NNTrainer.fix_linearizer(Linearizer.mazePoints, Linearizer.tsProj)
        # TODO: if target is not position, change the target
        NNTrainer.train(
            DataHelper.fullBehavior, windowsizeMS=windowSizeMS, isPredLoss=isPL
        )
        NNTrainer.test(
            DataHelper.fullBehavior,
            l_function=l_function,
            windowsizeMS=windowSizeMS,
            isPredLoss=isPL,
        )
        print_results.print_results(NNTrainer.folderResult, windowSizeMS=windowSizeMS)
        # Create json
        if isPL:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "predLossModel",
            )
        else:
            modelPath = os.path.join(
                NNTrainer.folderModels, str(windowSizeMS), "savedModels", "fullModel"
            )
        generate_json(ProjectPath, modelPath, DataHelper.list_channels)
        print("Saved json file for Julia thresholds and checkpoints.")

    elif mode == "decode":
        from decoder import decode
        from importData.juliaData.julia_data_parser import julia_spike_filter

        if not os.path.isfile(ProjectPath.json):
            sys.exit(
                "No .json file was found to pick up the network to decode."
                + " Please verify that you encoded the weights, and that "
                + "you json file has the same name as basefile.dat"
            )
        else:
            # Create data
            folderCode = os.path.dirname(os.path.realpath(__file__)) + os.path.sep
            # Right now, the thresholds are not the same
            julia_spike_filter(ProjectPath, folderCode, windowSize=args.window)
            # Decode
            Decoder = decode.Decoder(ProjectPath, Parameters)
            outputs = Decoder.test(
                DataHelper.fullBehavior,
                l_function=l_function,
                windowSizeMS=windowSizeMS,
            )
            print_results.print_results(Decoder.folderResult, windowSizeMS=windowSizeMS)

    elif mode == "compare":
        from fullEncoder import an_network as Training
        from importData.compareSpikeFiltering import WaveFormComparator
        from importData.juliaData.julia_data_parser import julia_spike_filter
        from openEphysExport.generate_json import generate_json
        from resultAnalysis import paper_figures
        from simpleBayes import decode_bayes as BayesTrainer

        ### Bayes
        TrainerBayes = BayesTrainer.Trainer(ProjectPath)
        bayesMatrices = TrainerBayes.train_order_by_pos(
            DataHelper.fullBehavior, l_function
        )

        ### ANN TODO: if exists
        folder_code = os.path.dirname(os.path.realpath(__file__)) + os.path.sep
        julia_spike_filter(ProjectPath, folder_code, windowSize=args.window)
        # Network
        NNTrainer = Training.LSTMandSpikeNetwork(
            ProjectPath, Parameters, deviceName=deviceName
        )
        NNTrainer.fix_linearizer(Linearizer.mazePoints, Linearizer.tsProj)
        NNTrainer.train(DataHelper.fullBehavior, windowSizeMS=windowSizeMS)
        NNTrainer.test(
            DataHelper.fullBehavior, l_function=l_function, windowSizeMS=windowSizeMS
        )
        if isPL:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "predLossModel.keras",
            )
        else:
            modelPath = os.path.join(
                NNTrainer.folderModels,
                str(windowSizeMS),
                "savedModels",
                "fullModel.keras",
            )
        generate_json(ProjectPath, modelPath, DataHelper.list_channels)

        ### Compare and align waveforms
        WFCTrain = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=True,
            windowSizeMS=windowSizeMS,
        )
        WFCTrain.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )
        WFCTest = WaveFormComparator(
            ProjectPath,
            Parameters,
            DataHelper.fullBehavior,
            useTrain=False,
            windowSizeMS=windowSizeMS,
        )
        WFCTest.save_alignment_tools(
            TrainerBayes, l_function, windowSizeMS=windowSizeMS
        )

        ### Figures
        figures = paper_figures.PaperFigures(
            ProjectPath,
            DataHelper.fullBehavior,
            TrainerBayes,
            l_function,
            bayesMatrices=bayesMatrices,
        )
        figures.load_data()
        figures.test_bayes()
        figures.fig_example_linear()
        figures.hist_linerrors()
        figures.nnVSbayes()
        figures.predLoss_vs_trueLoss()
        figures.fig_example_2d()
        figures.predLoss_linError()
        figures.predLoss_linError()
        figures.fig_example_linear_filtered()


if __name__ == "__main__":
    print()
    import argparse

    Parser = argparse.ArgumentParser(
        description="Creating and training an agent "
        + "to decode high level features from electrophysiology data."
    )
    subparsers = Parser.add_subparsers(
        dest="mode",
        title="modes",
        description="all existing modes of encoding",
        help="selects an encoding mode"
        + ". For more information type the mode name between neuroencoder and -h",
    )

    for cmd in ["ann", "bayes", "compare", "decode"]:
        p = subparsers.add_parser(cmd)
        p.add_argument("path", help="path to xml file", type=os.path.abspath)
        if cmd == "decode":
            p.add_argument("jsonPath", type=str, help="path to json file")
        p.add_argument(
            "-w",
            "--window",
            type=float,
            help="defines window size, in seconds. Defaults to 0.108",
            default=0.108,
        )
        p.add_argument(
            "-n",
            "--name",
            type=str,
            help="name of the folder where all models and results will be stored",
            default=str(cmd) + "_results",
        )

        p.add_argument(
            "-e",
            "--epochs",
            type=int,
            help="number of epochs for training. Defaults to 100",
            default=100,
        )
        if cmd != "bayes":
            p.add_argument(
                "-g",
                "--gpu",
                action="store_true",
                help="run computations on gpu. Requires specific installation.",
            )
            p.add_argument(
                "-pl",
                "--predicted_loss",
                action="store_false",
                help="defines whether another, predLoss only, "
                + "network will be train on the piece of data",
            )
            p.add_argument(
                "-t",
                "--target",
                type=str,
                help="name of feature to be decoded. Defaults are Xtsd and Ytsd. "
                + "Must be a tsd variable from behavResources.mat",
                default="pos",
            )
    args = Parser.parse_args()

    print()
    import shutil

    rows, columns = shutil.get_terminal_size()
    print("|| neuroEncoder by MOBS ||".center(rows))
    print("may 2020 - march 2022".center(rows))
    print("email: t.balenbois@gmail.com && bryzgalovdm@gmail.com".center(rows))
    print()
    print()
    print("{:=^40}".format("PARAMETERS").center(rows))
    for k, v in vars(args).items():
        print(f"{k}: {v}".center(rows))
    print("{:=^40}".format("END").center(rows))

    # TODO:  Check if split is not too optimistic
    if args.mode == "decode":
        print("Decoding of full dataset \n")

    if not (
        os.path.isfile(
            os.path.abspath(
                os.path.expanduser(
                    os.path.split(args.path)[0] + os.path.sep + "nnBehavior.mat"
                )
            )
        )
    ):
        # Get the tsd feature, i.e. a nnBehavior.mat file from the tsd feature.
        # The target is the name of the feature to be decoded, will default to the position.
        subprocess.run(
            [
                os.path.join(os.path.dirname(__file__), "getTsdFeature.sh"),
                os.path.abspath(os.path.expanduser(args.path.strip("'"))),
                "'" + args.target + "'",
            ]
        )
    print()

    main(args)

    print()
    print()
    print("Algo has done what it wanted to do.")
